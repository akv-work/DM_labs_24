import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.metrics import precision_score, classification_report, confusion_matrix
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
import warnings
warnings.filterwarnings('ignore')

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ Adult Census Income
def load_data():
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ Adult Census Income –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–æ—Ö–æ–¥–∞ (>50K –∏–ª–∏ <=50K)
    """
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
    from sklearn.datasets import make_classification
    X, y = make_classification(n_samples=1000, n_features=14, n_informative=10,
                              n_redundant=4, n_classes=2, random_state=42)

    # –ò–º–∏—Ç–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã Adult dataset
    feature_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
                    'marital-status', 'occupation', 'relationship', 'race',
                    'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']

    df = pd.DataFrame(X, columns=feature_names)
    df['income'] = y
    df['income'] = df['income'].map({0: '<=50K', 1: '>50K'})

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    categorical_cols = ['workclass', 'education', 'marital-status', 'occupation',
                       'relationship', 'race', 'sex', 'native-country']

    for col in categorical_cols:
        df[col] = np.random.choice(['A', 'B', 'C', 'Unknown'], size=len(df))

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤
    for col in ['workclass', 'occupation']:
        mask = np.random.random(len(df)) < 0.05  # 5% –ø—Ä–æ–ø—É—Å–∫–æ–≤
        df.loc[mask, col] = 'Unknown'

    return df

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
df = load_data()
print(f"–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {df.shape}")
print("\n–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
print(df.head())

print("\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ:")
print(df.info())

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
def preprocess_data(df):
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    """
    # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ø–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
    data = df.copy()

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
    X = data.drop('income', axis=1)
    y = data['income']

    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π —Å –ø–æ–º–æ—â—å—é LabelEncoder
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    numerical_features = ['age', 'fnlwgt', 'education-num', 'capital-gain',
                         'capital-loss', 'hours-per-week']
    categorical_features = ['workclass', 'education', 'marital-status', 'occupation',
                           'relationship', 'race', 'sex', 'native-country']

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
    for col in categorical_features:
        X[col] = X[col].fillna('Unknown')

    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), numerical_features),
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)
        ])

    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
    X_processed = preprocessor.fit_transform(X)

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–º–µ–Ω –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ OneHot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
    cat_encoder = preprocessor.named_transformers_['cat']
    feature_names = numerical_features + list(cat_encoder.get_feature_names_out(categorical_features))

    return X_processed, y_encoded, feature_names, preprocessor, label_encoder

# –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
print("–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
X_processed, y_encoded, feature_names, preprocessor, label_encoder = preprocess_data(df)

print(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {X_processed.shape}")
print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feature_names)}")

# –í—ã–≤–æ–¥ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –î–û –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
print("–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–æ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è:")
print(df['income'].value_counts())
print("–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –ø–æ—Å–ª–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è:")
unique, counts = np.unique(y_encoded, return_counts=True)
for val, count in zip(unique, counts):
    print(f"–ö–ª–∞—Å—Å {val} ('{label_encoder.inverse_transform([val])[0]}'): {count} samples")

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏ (–û–î–ò–ù –†–ê–ó!)
X_train, X_test, y_train, y_test = train_test_split(
    X_processed, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded
)

print(f"\n–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_train.shape[0]} samples")
print(f"–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_test.shape[0]} samples")

# –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π
def train_and_evaluate_models(X_train, X_test, y_train, y_test, label_encoder):
    """
    –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    """
    models = {
        'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=5),
        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
        'AdaBoost': AdaBoostClassifier(random_state=42),
        'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss'),
        'CatBoost': CatBoostClassifier(random_state=42, verbose=False)
    }

    results = {}

    for name, model in models.items():
        print(f"–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: {name}")

        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model.fit(X_train, y_train)

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
        y_pred = model.predict(X_test)

        # –†–∞—Å—á–µ—Ç precision –¥–ª—è –∫–ª–∞—Å—Å–∞ ">50K" (–∫–ª–∞—Å—Å 1 –ø–æ—Å–ª–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è)
        precision = precision_score(y_test, y_pred, pos_label=1)

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results[name] = {
            'model': model,
            'precision': precision,
            'classification_report': report,
            'predictions': y_pred
        }

        print(f"Precision –¥–ª—è '>50K': {precision:.4f}")
        print("-" * 50)

    return results

# –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π
print("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")
results = train_and_evaluate_models(X_train, X_test, y_train, y_test, label_encoder)

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ –≤—ã–≤–æ–¥—ã
def compare_models(results):
    """
    –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ –º–µ—Ç—Ä–∏–∫–µ precision –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–≤–æ–¥–æ–≤
    """
    print("=" * 70)
    print("–°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –ü–û –ú–ï–¢–†–ò–ö–ï PRECISION –î–õ–Ø –ö–õ–ê–°–°–ê '>50K'")
    print("=" * 70)

    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    comparison_df = pd.DataFrame({
        'Model': list(results.keys()),
        'Precision': [results[model]['precision'] for model in results]
    }).sort_values('Precision', ascending=False)

    print(comparison_df.to_string(index=False))

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    best_model_name = comparison_df.iloc[0]['Model']
    best_precision = comparison_df.iloc[0]['Precision']

    print(f"\n–õ–£–ß–®–ê–Ø –ú–û–î–ï–õ–¨: {best_model_name}")
    print(f"Precision: {best_precision:.4f}")

    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n" + "=" * 70)
    print("–ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    print("=" * 70)

    for model_name in results:
        precision = results[model_name]['precision']
        print(f"\n{model_name}:")
        print(f"  Precision (>50K): {precision:.4f}")

        # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è precision
        if precision > 0.8:
            print("  ‚úÖ –û—Ç–ª–∏—á–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å - –º–æ–¥–µ–ª—å —Ö–æ—Ä–æ—à–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –≤—ã—Å–æ–∫–∏–µ –¥–æ—Ö–æ–¥—ã")
        elif precision > 0.6:
            print("  ‚ö†Ô∏è  –•–æ—Ä–æ—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å - –ø—Ä–∏–µ–º–ª–µ–º–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏")
        else:
            print("  ‚ùå –ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å - –º–Ω–æ–≥–æ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π")

    return best_model_name, comparison_df

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
best_model, comparison_df = compare_models(results)

# –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
def analyze_best_model(results, best_model_name, X_test, y_test, label_encoder):
    """
    –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    """
    print("\n" + "=" * 70)
    print(f"–î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –õ–£–ß–®–ï–ô –ú–û–î–ï–õ–ò: {best_model_name}")
    print("=" * 70)

    best_result = results[best_model_name]
    model = best_result['model']
    y_pred = best_result['predictions']

    # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
    cm = confusion_matrix(y_test, y_pred)
    cm_df = pd.DataFrame(cm,
                        index=[f'–§–∞–∫—Ç {label}' for label in label_encoder.classes_],
                        columns=[f'–ü—Ä–æ–≥–Ω–æ–∑ {label}' for label in label_encoder.classes_])

    print("–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:")
    print(cm_df)
    print()

    # –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    print("–û—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
analyze_best_model(results, best_model, X_test, y_test, label_encoder)

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
import matplotlib.pyplot as plt
import seaborn as sns

def visualize_results(comparison_df, results, X_test, y_test, label_encoder):
    """
    –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
    """
    plt.style.use('default')
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))

    # –ì—Ä–∞—Ñ–∏–∫ 1: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ precision
    models = comparison_df['Model']
    precisions = comparison_df['Precision']

    bars = ax1.bar(models, precisions, color=['skyblue', 'lightcoral', 'lightgreen', 'gold', 'violet'])
    ax1.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ Precision –¥–ª—è –∫–ª–∞—Å—Å–∞ ">50K"', fontsize=14, fontweight='bold')
    ax1.set_ylabel('Precision')
    ax1.set_ylim(0, 1)
    ax1.tick_params(axis='x', rotation=45)

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
    for bar, precision in zip(bars, precisions):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{precision:.3f}', ha='center', va='bottom')

    # –ì—Ä–∞—Ñ–∏–∫ 2: –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    best_model_name = comparison_df.iloc[0]['Model']
    y_pred_best = results[best_model_name]['predictions']
    cm = confusion_matrix(y_test, y_pred_best)

    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax2,
                xticklabels=label_encoder.classes_,
                yticklabels=label_encoder.classes_)
    ax2.set_title(f'–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ - {best_model_name}', fontweight='bold')
    ax2.set_xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å')
    ax2.set_ylabel('–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –∫–ª–∞—Å—Å')

    plt.tight_layout()
    plt.show()

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
print("–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
visualize_results(comparison_df, results, X_test, y_test, label_encoder)

# –ó–∞–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—ã–µ –≤—ã–≤–æ–¥—ã
def print_final_conclusions(results, best_model):
    """
    –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤—ã—Ö –≤—ã–≤–æ–¥–æ–≤ –ø–æ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π —Ä–∞–±–æ—Ç–µ
    """
    print("=" * 70)
    print("–ó–ê–ö–õ–Æ–ß–ò–¢–ï–õ–¨–ù–´–ï –í–´–í–û–î–´")
    print("=" * 70)

    print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê:")
    print("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –ø–æ–∫–∞–∑–∞–ª–æ —Å–ª–µ–¥—É—é—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")

    for model_name in results:
        precision = results[model_name]['precision']
        print(f"  ‚Ä¢ {model_name}: Precision = {precision:.4f}")

    print(f"\nüéØ –õ–£–ß–®–ò–ô –ê–õ–ì–û–†–ò–¢–ú: {best_model}")
    print("–≠—Ç–æ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º –¥–µ–º–æ–Ω–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç –Ω–∞–∏–ª—É—á—à—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –≤ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ "
          "–ª—é–¥–µ–π —Å –¥–æ—Ö–æ–¥–æ–º >50K$ –≤ –≥–æ–¥")

# –ò—Ç–æ–≥–æ–≤—ã–µ –≤—ã–≤–æ–¥—ã
print_final_conclusions(results, best_model)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª
def save_results(results, comparison_df, filename='lab5_results.csv'):
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª
    """
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    comparison_df.to_csv('model_comparison.csv', index=False)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    detailed_results = []
    for model_name, result in results.items():
        detailed_results.append({
            'Model': model_name,
            'Precision': result['precision'],
            'Best_Model': 1 if model_name == best_model else 0
        })

    pd.DataFrame(detailed_results).to_csv(filename, index=False)
    print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª—ã: model_comparison.csv –∏ {filename}")

save_results(results, comparison_df)

print("\n" + "=" * 70)
print("–õ–ê–ë–û–†–ê–¢–û–†–ù–ê–Ø –†–ê–ë–û–¢–ê ‚Ññ5 –í–´–ü–û–õ–ù–ï–ù–ê!")
print("=" * 70)