import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_curve
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

warnings.filterwarnings('ignore')


# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ Bank Marketing
# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ Bank Marketing
def load_data():
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ Bank Marketing
    """
    try:
        # –°–ø–æ—Å–æ–± 1: –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ UC Irvine ML Repository
        from ucimlrepo import fetch_ucirepo
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ UCI repository...")
        bank_marketing = fetch_ucirepo(id=222)
        X = bank_marketing.data.features
        y = bank_marketing.data.targets
        df = pd.concat([X, y], axis=1)
        return df
    except Exception as e1:
        print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ UCI: {e1}")
        try:
            # –°–ø–æ—Å–æ–± 2: –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ CSV —Ñ–∞–π–ª–∞
            print("–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞...")
            df = pd.read_csv('bank.csv', delimiter=';')
            return df
        except Exception as e2:
            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª: {e2}")
            # –°–ø–æ—Å–æ–± 3: –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
            print("–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ...")
            return generate_synthetic_data()


# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö Bank Marketing...")
df = load_data()
print(f"–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {df.shape}")
print("\n–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
print(df.head())

print("\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ:")
print(df.info())

print("\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π:")
print(df['y'].value_counts())
print("\n–î–æ–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞: {:.2f}%".format(
    (df['y'] == 'yes').sum() / len(df) * 100))


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
def preprocess_data(df):
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    """
    # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ø–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
    data = df.copy()

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
    X = data.drop('y', axis=1)
    y = data['y']

    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    # –û–ë–ù–û–í–õ–ï–ù–ù–´–ï –°–ü–ò–°–ö–ò –ü–†–ò–ó–ù–ê–ö–û–í –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ Bank Marketing
    numerical_features = ['age', 'balance', 'day_of_week', 'duration', 'campaign', 'pdays', 'previous']

    categorical_features = ['job', 'marital', 'education', 'default', 'housing',
                            'loan', 'contact', 'month', 'poutcome']

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
    for col in categorical_features:
        if col in X.columns:
            X[col] = X[col].fillna('unknown')
        else:
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫ {col} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
    for col in numerical_features:
        if col in X.columns:
            X[col] = X[col].fillna(X[col].median())
        else:
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ß–∏—Å–ª–æ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫ {col} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö")

    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–±–æ—Ä–∞ —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
    def get_existing_columns(column_list, df_columns):
        return [col for col in column_list if col in df_columns]

    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ —Ç–æ–ª—å–∫–æ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —Å—Ç–æ–ª–±—Ü–∞–º–∏
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), get_existing_columns(numerical_features, X.columns)),
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False),
             get_existing_columns(categorical_features, X.columns))
        ])

    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
    X_processed = preprocessor.fit_transform(X)

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–º–µ–Ω –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ OneHot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
    feature_names = []

    # –î–æ–±–∞–≤–ª—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    feature_names.extend(get_existing_columns(numerical_features, X.columns))

    # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ—Å–ª–µ OneHot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
    if 'cat' in preprocessor.named_transformers_:
        cat_processor = preprocessor.named_transformers_['cat']
        if hasattr(cat_processor, 'get_feature_names_out'):
            categorical_processed_features = get_existing_columns(categorical_features, X.columns)
            feature_names.extend(cat_processor.get_feature_names_out(categorical_processed_features))

    return X_processed, y_encoded, feature_names, preprocessor, label_encoder


# –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
print("\n–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
X_processed, y_encoded, feature_names, preprocessor, label_encoder = preprocess_data(df)

print(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {X_processed.shape}")
print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feature_names)}")

# –í—ã–≤–æ–¥ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
print("\n–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –ø–æ—Å–ª–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è:")
unique, counts = np.unique(y_encoded, return_counts=True)
for val, count in zip(unique, counts):
    print(
        f"–ö–ª–∞—Å—Å {val} ('{label_encoder.inverse_transform([val])[0]}'): {count} samples ({count / len(y_encoded) * 100:.1f}%)")

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
X_train, X_test, y_train, y_test = train_test_split(
    X_processed, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded
)

print(f"\n–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_train.shape[0]} samples")
print(f"–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_test.shape[0]} samples")


# –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ F1-score
def train_and_evaluate_models(X_train, X_test, y_train, y_test, label_encoder):
    """
    –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ F1-score
    """
    models = {
        'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=6),
        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),
        'AdaBoost': AdaBoostClassifier(random_state=42),
        'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss',
                                 scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum()),
        'CatBoost': CatBoostClassifier(random_state=42, verbose=False, auto_class_weights='Balanced')
    }

    results = {}

    for name, model in models.items():
        print(f"–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: {name}")

        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model.fit(X_train, y_train)

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
        y_pred = model.predict(X_test)

        # –†–∞—Å—á–µ—Ç F1-score –¥–ª—è –∫–ª–∞—Å—Å–∞ "yes" (–∫–ª–∞—Å—Å 1 –ø–æ—Å–ª–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è)
        f1 = f1_score(y_test, y_pred, pos_label=1)

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        precision = precision_score(y_test, y_pred, pos_label=1)
        recall = recall_score(y_test, y_pred, pos_label=1)

        report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results[name] = {
            'model': model,
            'f1_score': f1,
            'precision': precision,
            'recall': recall,
            'classification_report': report,
            'predictions': y_pred
        }

        print(f"F1-score –¥–ª—è 'yes': {f1:.4f}")
        print(f"Precision –¥–ª—è 'yes': {precision:.4f}")
        print(f"Recall –¥–ª—è 'yes': {recall:.4f}")
        print("-" * 50)

    return results


# –ò–º–ø–æ—Ä—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
from sklearn.metrics import precision_score, recall_score

print("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")
results = train_and_evaluate_models(X_train, X_test, y_train, y_test, label_encoder)


# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ F1-score
def compare_models(results):
    """
    –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ –º–µ—Ç—Ä–∏–∫–µ F1-score –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–≤–æ–¥–æ–≤
    """
    print("=" * 80)
    print("–°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –ü–û –ú–ï–¢–†–ò–ö–ï F1-SCORE –î–õ–Ø –ö–õ–ê–°–°–ê 'yes'")
    print("=" * 80)

    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    comparison_df = pd.DataFrame({
        'Model': list(results.keys()),
        'F1-Score': [results[model]['f1_score'] for model in results],
        'Precision': [results[model]['precision'] for model in results],
        'Recall': [results[model]['recall'] for model in results]
    }).sort_values('F1-Score', ascending=False)

    print(comparison_df.to_string(index=False))

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –ø–æ F1-score
    best_model_name = comparison_df.iloc[0]['Model']
    best_f1 = comparison_df.iloc[0]['F1-Score']

    print(f"\n–õ–£–ß–®–ê–Ø –ú–û–î–ï–õ–¨ –ü–û F1-SCORE: {best_model_name}")
    print(f"F1-Score: {best_f1:.4f}")

    # –ê–Ω–∞–ª–∏–∑ –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–∞ –º–µ–∂–¥—É Precision –∏ Recall
    print("\n" + "=" * 80)
    print("–ê–ù–ê–õ–ò–ó –ö–û–ú–ü–†–û–ú–ò–°–°–ê –ú–ï–ñ–î–£ PRECISION –ò RECALL")
    print("=" * 80)

    for model_name in results:
        f1 = results[model_name]['f1_score']
        precision = results[model_name]['precision']
        recall = results[model_name]['recall']

        print(f"\n{model_name}:")
        print(f"  F1-Score: {f1:.4f}")
        print(f"  Precision: {precision:.4f}")
        print(f"  Recall: {recall:.4f}")

        # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if precision > recall:
            print("  ‚öñÔ∏è  –ú–æ–¥–µ–ª—å –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞ - –º–µ–Ω—å—à–µ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π, –Ω–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç –∫–ª–∏–µ–Ω—Ç–æ–≤")
        elif recall > precision:
            print("  ‚öñÔ∏è  –ú–æ–¥–µ–ª—å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞ - –Ω–∞—Ö–æ–¥–∏—Ç –±–æ–ª—å—à–µ –∫–ª–∏–µ–Ω—Ç–æ–≤, –Ω–æ —Å –±–æ–ª—å—à–∏–º —á–∏—Å–ª–æ–º –æ—à–∏–±–æ–∫")
        else:
            print("  ‚öñÔ∏è  –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å")

        if f1 > 0.5:
            print("  ‚úÖ –•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ - –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –±–∏–∑–Ω–µ—Å–∞")
        elif f1 > 0.3:
            print("  ‚ö†Ô∏è  –ü—Ä–∏–µ–º–ª–µ–º–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ - —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏")
        else:
            print("  ‚ùå –ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ - –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è")

    return best_model_name, comparison_df


# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
best_model, comparison_df = compare_models(results)


# –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
def analyze_best_model(results, best_model_name, X_test, y_test, label_encoder):
    """
    –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    """
    print("\n" + "=" * 80)
    print(f"–î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –õ–£–ß–®–ï–ô –ú–û–î–ï–õ–ò: {best_model_name}")
    print("=" * 80)

    best_result = results[best_model_name]
    model = best_result['model']
    y_pred = best_result['predictions']

    # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
    cm = confusion_matrix(y_test, y_pred)
    cm_df = pd.DataFrame(cm,
                         index=[f'–§–∞–∫—Ç {label}' for label in label_encoder.classes_],
                         columns=[f'–ü—Ä–æ–≥–Ω–æ–∑ {label}' for label in label_encoder.classes_])

    print("–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:")
    print(cm_df)
    print()

    # –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    print("–û—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

    # –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
    if hasattr(model, 'feature_importances_'):
        print("\n–¢–æ–ø-15 —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        try:
            importances = model.feature_importances_

            # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame —Å –≤–∞–∂–Ω–æ—Å—Ç—è–º–∏
            feature_imp_df = pd.DataFrame({
                'feature': feature_names,
                'importance': importances
            }).sort_values('importance', ascending=False)

            print(feature_imp_df.head(15).to_string(index=False))

        except Exception as e:
            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")


# –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
analyze_best_model(results, best_model, X_test, y_test, label_encoder)


# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
def visualize_results(comparison_df, results, X_test, y_test, label_encoder):
    """
    –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
    """
    plt.style.use('default')
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 14))

    # –ì—Ä–∞—Ñ–∏–∫ 1: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ F1-score
    models = comparison_df['Model']
    f1_scores = comparison_df['F1-Score']

    bars = ax1.bar(models, f1_scores, color=['skyblue', 'lightcoral', 'lightgreen', 'gold', 'violet'])
    ax1.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ F1-Score –¥–ª—è –∫–ª–∞—Å—Å–∞ "yes"', fontsize=14, fontweight='bold')
    ax1.set_ylabel('F1-Score')
    ax1.set_ylim(0, 1)
    ax1.tick_params(axis='x', rotation=45)

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
    for bar, score in zip(bars, f1_scores):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width() / 2., height + 0.01,
                 f'{score:.3f}', ha='center', va='bottom')

    # –ì—Ä–∞—Ñ–∏–∫ 2: –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    best_model_name = comparison_df.iloc[0]['Model']
    y_pred_best = results[best_model_name]['predictions']
    cm = confusion_matrix(y_test, y_pred_best)

    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax2,
                xticklabels=label_encoder.classes_,
                yticklabels=label_encoder.classes_)
    ax2.set_title(f'–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ - {best_model_name}', fontweight='bold')
    ax2.set_xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å')
    ax2.set_ylabel('–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –∫–ª–∞—Å—Å')

    # –ì—Ä–∞—Ñ–∏–∫ 3: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ Precision-Recall
    precisions = comparison_df['Precision']
    recalls = comparison_df['Recall']

    x = np.arange(len(models))
    width = 0.35

    ax3.bar(x - width / 2, precisions, width, label='Precision', alpha=0.7)
    ax3.bar(x + width / 2, recalls, width, label='Recall', alpha=0.7)

    ax3.set_xlabel('–ú–æ–¥–µ–ª–∏')
    ax3.set_ylabel('Score')
    ax3.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ Precision –∏ Recall', fontweight='bold')
    ax3.set_xticks(x)
    ax3.set_xticklabels(models, rotation=45)
    ax3.legend()
    ax3.set_ylim(0, 1)

    # –ì—Ä–∞—Ñ–∏–∫ 4: –ö—Ä–∏–≤–∞—è Precision-Recall –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    best_model_obj = results[best_model_name]['model']
    if hasattr(best_model_obj, 'predict_proba'):
        y_proba = best_model_obj.predict_proba(X_test)[:, 1]
        precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_proba, pos_label=1)

        ax4.plot(recall_curve, precision_curve, marker='.')
        ax4.set_xlabel('Recall')
        ax4.set_ylabel('Precision')
        ax4.set_title(f'Precision-Recall –∫—Ä–∏–≤–∞—è - {best_model_name}', fontweight='bold')
        ax4.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()


# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
print("\n–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
visualize_results(comparison_df, results, X_test, y_test, label_encoder)


# –ó–∞–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—ã–µ –≤—ã–≤–æ–¥—ã
def print_final_conclusions(results, best_model, comparison_df):
    """
    –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤—ã—Ö –≤—ã–≤–æ–¥–æ–≤ –ø–æ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π —Ä–∞–±–æ—Ç–µ
    """
    print("=" * 80)
    print("–ó–ê–ö–õ–Æ–ß–ò–¢–ï–õ–¨–ù–´–ï –í–´–í–û–î–´")
    print("=" * 80)

    print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê:")
    print("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –ø–æ–∫–∞–∑–∞–ª–æ —Å–ª–µ–¥—É—é—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (F1-score –¥–ª—è –∫–ª–∞—Å—Å–∞ 'yes'):")

    for _, row in comparison_df.iterrows():
        print(f"  ‚Ä¢ {row['Model']}: F1 = {row['F1-Score']:.4f}, "
              f"Precision = {row['Precision']:.4f}, Recall = {row['Recall']:.4f}")

    best_result = results[best_model]

    print(f"\nüéØ –õ–£–ß–®–ò–ô –ê–õ–ì–û–†–ò–¢–ú: {best_model}")
    print(f"F1-Score: {best_result['f1_score']:.4f}")
    print(f"Precision: {best_result['precision']:.4f}")
    print(f"Recall: {best_result['recall']:.4f}")

    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
    print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –ë–ò–ó–ù–ï–°–ê:")

    if best_result['precision'] > best_result['recall']:
        print("‚Ä¢ –ú–æ–¥–µ–ª—å –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞ - –º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è")
        print("‚Ä¢ –ü–æ–¥—Ö–æ–¥–∏—Ç –∫–æ–≥–¥–∞ —Å—Ç–æ–∏–º–æ—Å—Ç—å –∫–æ–Ω—Ç–∞–∫—Ç–∞ —Å –∫–ª–∏–µ–Ω—Ç–æ–º –≤—ã—Å–æ–∫–∞")
        print("‚Ä¢ –≠–∫–æ–Ω–æ–º–∏—Ç —Ä–µ—Å—É—Ä—Å—ã, –Ω–æ –º–æ–∂–µ—Ç —É–ø—É—Å–∫–∞—Ç—å —á–∞—Å—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤")
    elif best_result['recall'] > best_result['precision']:
        print("‚Ä¢ –ú–æ–¥–µ–ª—å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞ - –Ω–∞—Ö–æ–¥–∏—Ç –±–æ–ª—å—à–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤")
        print("‚Ä¢ –ü–æ–¥—Ö–æ–¥–∏—Ç –∫–æ–≥–¥–∞ –≤–∞–∂–Ω–æ –Ω–µ —É–ø—É—Å—Ç–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞")
        print("‚Ä¢ –¢—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ —Ä–µ—Å—É—Ä—Å–æ–≤ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π")
    else:
        print("‚Ä¢ –ú–æ–¥–µ–ª—å —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∞ - —Ö–æ—Ä–æ—à–∏–π –∫–æ–º–ø—Ä–æ–º–∏—Å—Å –º–µ–∂–¥—É —Ç–æ—á–Ω–æ—Å—Ç—å—é –∏ –ø–æ–ª–Ω–æ—Ç–æ–π")
        print("‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –±–∏–∑–Ω–µ—Å-–∑–∞–¥–∞—á")

    print(f"\nüìà –ü–†–ê–ö–¢–ò–ß–ï–°–ö–ê–Ø –ó–ù–ê–ß–ò–ú–û–°–¢–¨:")
    print(f"–ú–æ–¥–µ–ª—å {best_model} –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –ª—É—á—à–∏–π –∫–æ–º–ø—Ä–æ–º–∏—Å—Å –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤")
    print("–∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤–æ–π –∫–∞–º–ø–∞–Ω–∏–∏ –±–∞–Ω–∫–∞.")


# –ò—Ç–æ–≥–æ–≤—ã–µ –≤—ã–≤–æ–¥—ã
print_final_conclusions(results, best_model, comparison_df)


# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª
def save_results(results, comparison_df, filename='bank_marketing_results.csv'):
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª
    """
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    comparison_df.to_csv('bank_marketing_comparison.csv', index=False)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    detailed_results = []
    for model_name, result in results.items():
        detailed_results.append({
            'Model': model_name,
            'F1_Score': result['f1_score'],
            'Precision': result['precision'],
            'Recall': result['recall'],
            'Best_Model': 1 if model_name == best_model else 0
        })

    pd.DataFrame(detailed_results).to_csv(filename, index=False)
    print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª—ã: bank_marketing_comparison.csv –∏ {filename}")


save_results(results, comparison_df)

print("\n" + "=" * 80)
print("–õ–ê–ë–û–†–ê–¢–û–†–ù–ê–Ø –†–ê–ë–û–¢–ê ‚Ññ5 –í–´–ü–û–õ–ù–ï–ù–ê!")
print("=" * 80)